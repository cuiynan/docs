[TOC]
# 服务器

## CentOS7.6.1810
1. VM 安装后，默认上不了网， 需要更改：
	vim /etc/sysconfig/network-scripts/ifcfg-ens33中更改"ONBOOT=yes"，便可。	
2. 更改阿里源
```
	cd /etc/yum.repos.d/
	mv CentOS-Base.repo CentOS-Base.repo.20190626
	wget http://mirrors.aliyun.com/repo/Centos-7.repo
	yum clean all
	yum makecache
```
使用yum update进行验证，下方信息表示成功切换到阿里源了 。
```
Loading mirror speeds from cached hostfile
 * base: mirrors.aliyun.com
 * extras: mirrors.aliyun.com
 * updates: mirrors.aliyun.com
```
3.

## K8S
### centeros 7.6.1810

### 项目中使用

ingress/comployment/service/pod

#### 安装
##### 前提
1. 关闭swap
$ vim /etc/fstab # swap注释或者临时关闭swapoff -a
1. 关闭selinux
$ vim /etc/sysconfig/selinux # 使得 selinux=disabled
1. 关闭firewalld
$  chkconfig firewalld off
$ systemctl stop firewalld
##### 正式开始安装
K8S镜像地址：

	> https://github.com/kubernetes/kubernetes/releases

1. 创建k8s.repo源
	vi /etc/yum.repos.d/k8s.repo，内容如下
```
[kubernetes]
name=Kubernetes Repository
baseUrl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/
gpgcheck=1
gpgKey=https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg

保存后，使用yum repolist来查看是否设置成功。如下信息表示OK Kubernetes Repository           kubernetes 363
```
2.安装K8S

```
	yum install kubeadm kubectl kubeadm kubernetes-cni
	systemctl enable kubelet && systemctl start kubelet
	yum install docker
	systemctl enable docker && systemctl start docker
```
3. 下载 k8s所需的镜像 
$ kubeadm config images list #来查看本版本的kubenetes所需要的镜像及版本信息,由于$ kubeadm config images pull # 在k8s.gcr.io国内访问不了，故下述命令从docker库下载。
```
kubeadm config images list |sed -e 's/^/docker pull /g' -e 's#k8s.gcr.io#docker.io/mirrorgooglecontainers#g' |sh -x

docker images |grep mirrorgooglecontainers |awk '{print "docker tag ",$1":"$2,$1":"$2}' |sed -e 's#docker.io/mirrorgooglecontainers#k8s.gcr.io#2' |sh -x

docker images |grep mirrorgooglecontainers |awk '{print "docker rmi ", $1":"$2}' |sh -x

docker pull coredns/coredns:1.3.1
docker tag coredns/coredns:1.3.1 k8s.gcr.io/coredns:1.3.1
docker rmi coredns/coredns:1.3.1
```
4. 运行初始化K8S
```
# 配置转发相关参数，否则可能会出错
cat <<EOF > /etc/sysctl.d/k8s.conf
net.bridge.bridge-nf-call-ip6tables = 1
net.bridge.bridge-nf-call-iptables = 1
vm.swappiness=0
EOF
# 这里按回车，下面是第二条命令
sysctl --system

kubeadm init --kubernetes-version="v1.15.0" --dry-run --ignore-preflight-errors="Swap" 
#开始执行
kubeadm init --kubernetes-version="v1.15.0" --ignore-preflight-errors="Swap"
```
5. 使用
* 子节点加入命令
  kubeadm join 192.168.176.128:6443 --token reo788.sy04g31cpnqjct9o      --discovery-token-ca-cert-hash sha256:3ab482a78f9b2482d09ed1e7d21a9fdea864fa35658dab0997e3a9c58bd9e689 
*  master主机中查看节点加入情况，不错。
    kubectl get nodes -o wide
*  #若token过期
    kubeadm token list
    #重新生成 
    kubeamd token creat 
    #生成后查看其 --discovery-token-ca-cert-hash
    openssl x509 -pubkey -in /etc/kubernetes/pki/ca.crt | openssl rsa -pubin -outform der 2>/dev/null | openssl dgst -sha256 -hex | sed 's/^.* //'  
6. 问题
```	
	* 当出现NoReady时，查看kubelet运行日志
	journalctl -f -u kubelet
	* 当出现cni时
	vim /usr/lib/systemd/system/kubelet.service.d/10-kubeadm.conf 更改后续百度
	systemctl enable kubelet && systemctl start kubelet
	* 清空时，需要清空/var/lib/etcd,~/.kube/两个目录，否则提示etcd，authority等错误信息。
	kubeadmin reset
	rm -rf /var/lib/etcd/
	rm -rf /root/.kube/
```

### ubuntu
之前做的，现在看来不是很靠谱。
由于google国内访问不了，故使用阿里源进行安装。
官网地址：https://kubernetes.io/zh/docs/setup/independent/install-kubeadm/

```
apt-get update && apt-get install -y apt-transport-https
curl https://mirrors.aliyun.com/kubernetes/apt/doc/apt-key.gpg | apt-key add - 
cat <<EOF >/etc/apt/sources.list.d/kubernetes.list
deb https://mirrors.aliyun.com/kubernetes/apt/ kubernetes-xenial main
EOF  
apt-get update
apt-get install -y kubelet kubeadm kubectl
```
2019年2月18日 19:53 博晖2层

# Python
## 基本语法
> raise抛出异常、 try....except捕获
> 
## 爬虫
使用框架Scrapy进行，看示例比JAVA使用爽很多。

## web
使用bottle和 beaker.middleware，进行。项目代码非常简洁，不错。

## FastDFS
//todo

## MQTT
MQTT（Message Queuing Telemetry Transport，消息队列遥测传输协议），是一种基于发布/订阅（publish/subscribe）模式的"轻量级"通讯协议，该协议构建于TCP/IP协议上，由IBM在1999年发布。MQTT最大优点在于，可以以极少的代码和有限的带宽，为连接远程设备提供实时可靠的消息服务。作为一种低开销、低带宽占用的即时通讯协议，使其在物联网、小型设备、移动应用等方面有较广泛的应用。
### 主要特征
（1）使用发布/订阅消息模式，提供一对多的消息发布，解除应用程序耦合。
（2）对负载内容屏蔽的消息传输。
（3）使用TCP/IP提供网络连接。
（4）有三种消息发布服务质量：
	a. 至少一次，因网络原因，有可能会出现重复消息。(程序中设置QoS<=1,通常为0)
	b. 至多一次，若设备没有联系网络的原因，有可能会丢失消息。(QoS>=1)
	c. 只有一次，即高质量消息发布，保证客户端收到且仅一有条消息。 (QoS=1)
（5）小型传输，开销很小（固定长度的头部是2字节），协议交换最小化，以降低网络流量。
（6）使用Last Will和Testament特性通知有关各方客户端异常中断的机制。
### 实现原理
实现MQTT协议需要客户端和服务器端通讯完成，在通讯过程中，MQTT协议中有三种身份：发布者（Publish）、代理（Broker，即服务器）、订阅者（Subscribe）。MQTT传输的消息分为：主题（Topic）和负载（payload）两部分：
a. Topic，可以理解为消息的类型，订阅者订阅（Subscribe）后，就会收到该主题的消息内容（payload）；
b. payload，可以理解为消息的内容，是指订阅者具体要使用的内容。
### 总结
在众多实现版本中，《数字医生》本项目中我们使用的是Eclipse Paho。其拥有简洁的代码实现，心跳仅有2个字节处理。详细参考https://blog.csdn.net/yangzl2008/article/details/8861069

## git 
scope分为：
1. provided      用于编译环境，如容器或JDK已提供时servlet.jar，打包时不会打入。
2. test   	       适用于测试场景，在打包时不会打入。
3. system	 本地依赖，不向maven库中再去down，如第三方公司提供的短信jar，不推荐使用，需要时，上传到私服 。
4. compile	  当scope没有时，默认此项，打包时自动将依赖打入总jar包。
5. runtime       编译时不需要此包，运行时需要，如 jdbc-driver，最终会一起打入包中。
其中，provided具有传递性。

# Spring系

Java fluent风格   2019年2月22日

##  Swagger 
与springboot直接进行集成，部署：
1. pom.xml增加依赖2个相关依赖
2. Application启动时增加@EnableSwagger2
3. 直接在controller中使用。
4. IE http://localhost:8080/swagger-ui.html#/
上边遇到的坑： @GetMapping("")必须有路径，没有也要写上""。

## <a name="JAVA"> JAVA</a>
- **ArrayList LinkedList区别**
	ArrayList在源码中以数组形式展现，读快，写慢；linkedList源码中以Node形式，读慢，写快。
- **Stack** 
    Stack是一个后进先出（last in first out，LIFO）的堆栈.
- **对象的序列化**  
	作用：使用RMI在网络上使用或将对象保存至文件或数据库中,应用场景是分布式访问对象，使用浅复制或深复制。
	注意：不是所有的对象都会序列化，被static/transient修饰的对象并不被序列化。
	名义：序列化指将对象实现输出流；反序列化是指将对象流读出；

序列化原理，其实在使用时仅仅是对象implements Searializable便可:
其中serialVersionUID是序列化后兼容问题使用的，具体就是提供方如果更改后，使用方没有同步，使用方则会提示错误，如果两边一致，则正常运行。
- 序列化：

```
	FileOutputStream f = new FileOutputStream(“tmp”);//创建一个包含恢复对象(即对象进行反序列化信息)的”tmp”数据文件  
	ObjectOutputStream s = new ObjectOutputStream(f);   
	s.writeObject(“Today”); //写入字符串对象;   
	s.writeObject(new Date()); //写入瞬态对象;   
	s.flush(); 
```
- 反序列化:

```
　      FileInputStream in = null;
    in = new FileInputStream("tmp");
    ObjectInputStream s = new ObjectInputStream(in); 
　　 String today = (String)s.readObject(); //恢复对象; 
　 　Date date = (Date)s.readObject(); 
```
- **Session的持久化**
 访问过多的服务器服务时，服务器(tomcat)会因过多访问将保留很多httpSession，即使客户端关闭浏览器，tomcat也不会及时释放内存，为了不会引起内存溢出，运行服务器将不再使用的httpSession写入至文件或数据库中，这个过程就称为session的持久化。 

- **接口标准**  
	QPS:每秒查询率  
	TPS：Transactions Per Second（每秒传输的事物处理个数)

```
	100 <QPS <=N，  Time：<5ms  
	20<QPS <=100，  Time：<10ms  
	10 <QPS <=20，  Time：<20ms  
	5   <QPS <=10， Time：<50ms 
	0   <QPS <=5，  Time：<100ms  
```
- **容器启动时自动加载 ** 
在JDK5以后，增加@PostConstruct与@PreDestroy两个注解。  
	* @PostConstruct
这两个注解被用来修饰一个非静态的void()方法 。
    * @PreDestroy
加载servlet->servlet构造->postStructure->init->service->destory-PreDestory-服务器卸载servlet.  

如:
```
@PostConstruct
Public void someMethod() {}
或
public @PostConstruct void someMethod(){}
```

### 泛形 ###
<T> 常用于指定类型，如List<T> List<Student>/List<Teacher>单独使用都可以。
<?> 通常不确定类型List<Student>和List<Teacher>可以一起使用。还有extends的情况，如下：
List<? extends E> al=new ArrayList<? extends E>();
            泛型的限定：
               ? extends E:接收E类型或者E的子类型。
               ？super E:接收E类型或者E的父类型。
通过以下便能看出实质区别：               
```
   List<Student> list1 = new ArrayList<>();
   list1.add(new Student("zhangsan",18,0));
   list1.add(new Student("lisi",28,0));
   list1.add(new Student("wangwu",24,1));
   //这里如果add(new Teacher(...));就会报错，因为我们已经给List指定了数据类型为Student
   show1(list1);

   System.out.println("************分割线**************");

   //这里我们并没有给List指定具体的数据类型，可以存放多种类型数据
   List list2 = new ArrayList<>();
   list2.add(new Student("zhaoliu",22,1));
   list2.add(new Teacher("sunba",30,0));
   show2(list2);
```

###  java 多线程 ###
1. volatile与不加volatile的区别：
   当多线程时，
	某一线程对变量改变时，其它线程会在第一时间在内存中读取。不加时，其它线程不会在第一时间得到此变更，会从缓存中读取。
    也就是volaitle修饰的变量，线程操作时，取的都是不同线程中操作最后的最新的值。

1. ThreadLocal指定的变更，并不会引起像上述所说的问题，它为每一个线程的变量开启一块内存，变量在线程执行时，并不会相互影响。
 	> 参考：https://www.cnblogs.com/ldq2016/p/9041856.html
 	>
 	>  	>内部实现使用ThreadLocalMap进行，具体部分内部源码:
 ```
 public T get() {
        Thread t = Thread.currentThread();
        ThreadLocalMap map = getMap(t);
        if (map != null) {
            ThreadLocalMap.Entry e = map.getEntry(this);
            if (e != null) {
                @SuppressWarnings("unchecked")
                T result = (T)e.value;
                return result;
            }
        }
        return setInitialValue();
}
public void set(T value) {
    Thread t = Thread.currentThread();
    ThreadLocalMap map = getMap(t);
    if (map != null)
    map.set(this, value);
    else
    createMap(t, value);
}
public void remove() {
    ThreadLocalMap m = getMap(Thread.currentThread());
    if (m != null)
    m.remove(this);
}
private T setInitialValue() {
    T value = initialValue();
    Thread t = Thread.currentThread();
    ThreadLocalMap map = getMap(t);
    if (map != null)
    map.set(this, value);
    else
    createMap(t, value);
    return value;
}
 ```
1. java 实现线程有几种方式：
	如：implements Runnable、extends Thread。

1. synchronized与lock的区别
	synchronized是隐式加锁，加在方法体或方法体内；lock是显示加锁，加在方法体内；
	乐观锁是指比较乐观，读时认为没有线程在修改，会当在update时，加锁； 
	悲观锁是任何时候都是线程不安全的，全部加锁，性能低下。
1. ThreadLocal为每个线程创建一块共享区域，此区域为单线程共享，多线程安全。有set(Object)/get()/remove()/initValue()四个方法，其中remove用于垃圾回收。
	
- **Hibernate JPA 与 hibernate  区别**  
-   > 注意事项：
-   	1. @Cloumn（name = “userName”）JPA会自动在数据库中查找user_name字段。
-   	
	　	1，当JPA在merge时，会与缓存中的对象进行merge；但在hibernate中却是不会merge。如：
	> Cus cus = new Cus();  
	> cus.setName("test");  
	> cus.setId(1);   
	> Cus cus2 = em.find(Cus.class,1);  
	> em.merge(cus); //此时hibernate会报错，但在hibernate JPA中不会报错且会修改成功。
	
	2，查找缓存/数据库中新对象 是否存在，不存在插入；如果缓存中没有，数据库中有，会先查再复制后UPDATE; 如果缓存中有，数据库有，也是update。

- **Hibernate JPA 关系 **
	1，单向多对一
	MoneyToOne 在保存时，先保存1端，再保存多端， 否则会增加N条udpate语句（即update多端的外键ID）；删除时，不能删除1端， 因为有主外键关系。
	> @MonyToOne(fetch="lazy") //可使用懒加载  
	> @JoinColumn(name="id")  
	> public Custom getCustom(){  
	>     return this.custome;  
	> }  

  	2，单向一对多
	执行保存时，肯定会多出N条update,因为一端在保存时不会同时插入外键列。
	执行查询时，默认使用懒加载策略；也可手动更改使用左外连接查询，如EAGER。
	执行删除时，如果删除1端默认会先将N端外键置空再删1端记录。如果使用级联删除，使用@OneToMany(casecade = {CasecadeType.REMOVE})便可。
	> @OneToMany   
	> @JoinColumn(name="id")  
	> public Set getOrders(){  
	>    return this.orders;  
	> }  
	
	3，双向多对一
	执行保存时，先保存N端，再保存1端，会多出N*2条update;先保存 1端再保存N端，会减少update语句。一般会这样，使用多的一方维护关联关系，1的一方放弃维护关联关系。
	>
	>@OneToMany(mappedBy="多一方的变更名称")且不使用@JoinColumn.   
	
	4,双向一对一
	@OneToOne，需要添加unique=true。
	执行查询时，获取关联关系的一方时，必须使用懒加载方式，否则默认会使用左外连接执行。在获取非关联对象时，建议不使用懒加载（因为使用的话，会多一条select）。
	
	> @OneToOne
	> @JoinColum(name="",unique=true) // 维护关系的一方
	> 
	> @OneToOne(mappedBy="...") //不维护关联关系的一方 
	
	综上，当保存时先保存没有维护关系的一方。
	5，双向多对多	
	查询时，默认使用懒加载，且使用inner join进行查询

	>不维护关系一方
	>@ManyToMany(name="维护关系一方的变量名称")
	>维护关系一方
	>@ManyToMany
	>@JoinTable(name="表名称",JoinColumn = {@JoinColumn(name="维护关系表中的外键名称",referenceColumnName="非关系表中在关系表中的名称"),inverseJoinColumns={@JoinColumn(name="非维护关系表中的外键名称",referenceColumnName="非维护关系表中关联关系的字段名称")})
	

 **Hibernate JPA 默认支持一级缓存 **

	如果需要使用二级缓存，需要进行配置ehcache.xml及persisce.xml,
	在实体烦躁@CachEnable(true)
	persisce.xml中 true及hibernate 的二级缓存。

** JPQL **	

	使用缓存，前提在配置 文件中启用hibernate的缓存
	em.createQuery.setHint(QueryHints.CACHEABLE, true); 如果查询几条语句，启用后会发送一条SQL。
	left outer join fetch

- **springmvc4扫描@Service导致@Transactional注解无效的解决方案 **
##### 多条件查询
1. 当多条件查询时，判断为空时，可以使用下方代码进行：
	if(?1 !='',x1=?1,1=1) 代表传入的参数X1如果不为""（Spring类型空是""而不是null）将参数传入x1，如果为空时显示1=1 代表参数为真，对查询结果不产生作用。
```
Query=(" select * from xxx  where hp.del_flag <> '1' and  if (:hospitalName= '',1=1,hp.hospital_fullName like %:hospitalName%)  ORDER BY  ?#{#pageable}", nativeQuery = true)
List<Object[]> findHospitalLikeFullName( @Param("hospitalName") String hospitalName, Pageable pageable);
```

** Spring **  
	***** 实现读写分离*****    
	使用spring aop功能，在事务上使用readOnly=true来设置去读的操作。具体需要再细查。  
	***** 线程安全*****  
	spring在源码封闭时使用大量ThreadLocal类使其变量变为线程安全的。在我们正常开发时应避免使用公用变量，这样会引起线程不安全，如果必须使用，请在变量上增加 Map map = Collections.synchronizedMap(new HashMap());


## SpringBoot

* spring中事件可以监听，如：
    1，继承ApplicationEvent，
    2，实现ApplicationListener或使用注释@EventListener加至方法上，并对ApplicationEvent进行监听。

## RESFUL

- **Resful对应的method如下：**
> GET（SELECT）：从服务器取出资源（一项或多项）。  
> POST（CREATE）：在服务器新建一个资源。  
> PUT（UPDATE）：与patch同为update,区别幂等，更新传全部属性的值。  
> PATCH（UPDATE）：与put同为update,区别不幂等，更新只传更新的值。  
> DELETE（DELETE）：从服务器删除资源。  








## linux
```
     命名 ：
        //查看系统版本
	#uname -a

```



## kubernetes
1. 由于google需要翻墙，使用国内源进行下载，已验证ubuntu。：

> ### Debian / Ubuntu
apt-get update && apt-get install -y apt-transport-https
curl https://mirrors.aliyun.com/kubernetes/apt/doc/apt-key.gpg | apt-key add - 
cat <<EOF >/etc/apt/sources.list.d/kubernetes.list
deb https://mirrors.aliyun.com/kubernetes/apt/ kubernetes-xenial main
EOF  
apt-get update
apt-get install -y kubelet kubeadm kubectl
> ### CentOS / RHEL / Fedora
cat <<EOF > /etc/yum.repos.d/kubernetes.repo
[kubernetes]
name=Kubernetes
baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/
enabled=1
gpgcheck=1
repo_gpgcheck=1
gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg
EOF
setenforce 0
yum install -y kubelet kubeadm kubectl
systemctl enable kubelet && systemctl start kubelet

2.  编辑脚本pull.sh，存储以下内容 ：
```
for i in `kubeadm config images list`; do
  imageName=${i#k8s.gcr.io/}
  docker pull registry.aliyuncs.com/google_containers/$imageName
  docker tag registry.aliyuncs.com/google_containers/$imageName k8s.gcr.io/$imageName
  docker rmi registry.aliyuncs.com/google_containers/$imageName
done;
```
并执行./pull.sh，上述将K8S相关的容器下载至docker中。

3. 执行 #kubeadm init --kubernetes-version=v1.14.0 --pod-network-cidr=10.244.0.0/16即安装K8S完成 。
4. 

安装过程中遇到 的问题：
1. 由于装了etcd一直报错，当执行kubeadm init时报错如下：
```

[init] Using Kubernetes version: v1.14.0
[preflight] Running pre-flight checks
error execution phase preflight: [preflight] Some fatal errors occurred:
        [ERROR Port-2379]: Port 2379 is in use
        [ERROR Port-2380]: Port 2380 is in use
        [ERROR DirAvailable--var-lib-etcd]: /var/lib/etcd is not empty
[preflight] If you know what you are doing, you can make a check non-fatal with `--ignore-preflight-errors=...`
```
解决方法:apt remove etcd


## docker
1,端口映射

```
iptables -t nat -A  DOCKER -p tcp --dport 6379 -j DNAT --to-destination 172.17.0.4:6379
​```

2,获得docker容器IP
​```
docker inspect ba7 | grep IPAddress
​```

3,运行命令
​```
     docker search httpd //查找目前的源
     docker pull centos/httpd  //下载安装至image

	//载入
	docker load < /home/xx.tar
	docker images
	
	//容器启动
	docker run -p 8888:8080 -ti -d -v /data/:/data himoca/java /bin/bash //将本地磁盘挂载至容器中
  // redis:5.0.3从容器中启动
   docker run -p 6379:6379  -v /data/redis/conf/redis.conf:/etc/redis/redis.conf -v /data/redis/data:/data --name redis -d redis:5.0.3 redis-server /etc/redis/redis.conf
   // -d 后台运行哪个容器  -v路径带到容器中  -p端口映射 --name重命名 最后执行哪个命令及指定哪个配置文件。


    docker exec -ti xxx /bin/bash //后台运行
    
    //获得容器IP
    docker inspect --format='{{.NetworkSettings.IPAddress}}'  02f
    
    docker commit 5bd newName//保存镜像至image
	# 删除全部images，换成docker ps 就是删除全部正在运行的容器    
    docker rmi -f  $(docker images) 

```

4,docker结构  

	a.守护进程  
	b.客户端  
	c.内部结构：  
		1，镜像 images  
		2,仓库  regesiter  
		3,容器  container  

##  Redis
* redis主备直接使用 slaveof命令，如果使用集群，需要至少3个节点进行设计。使用以下命令来进行设置：
​```
redis-cli  --cluster create  192.168.131.131:6379 192.168.131.131:6381 192.168.131.131:6380
​```
* 当超过内存50G以上时，REDSI在读、存时会出现恢复时间长、主从切换慢、缓冲区满等问题，这 时可以考虑使用PINK(github 地址：https://github.com/baotiao/pink).  

* 存储中文时，返回base64编码 ，进行 #redis-cli --raw进入后，会显示中文。

1. **Redis类型有五种**  
	STRING(set key /get key)  
    Lists(lpush key value/ lpop key value / rpush key /rpop key/截取：lrang key 0 -1)  
    Hashes (hset key n1 v1 n2 v2..../hget key n2/scard key多少个元素)  
    Sorted Set	(zadd key int vavlue/zrange key 0,-1])  
2. 配置文件  
     CONFIG set requirepass "" // 设置密码  
     CONFIG get requirepass //获得密码
3. 持久化
  	1. RDB(Redis Database)

    	恢复时，速度更快。  
        保存RDB时，REDIS会fork一个子进程，单独去执行RDB的备份。提高REDIS性能。  
        Save时，可以通过配置定义隔几份钟保存一次，最快是1分钟10000keys changed便会触发。  
        
        缺点：丢数据。  
        
        save配置文件：  
        	save [seconds] [changes]  
    2. AOF(Append  Only File)  
    	只记录写操作；  
        可配置fsync策略：无fsync,每秒fsync,每次写的时候fsync.使用默认的每秒fsync策略  
        使用flushAll命令，也可恢复。方法：使用导出来的AOF去除末尾的 FLUSHALL命令便可。  
        缺点：文件大，恢复速度慢。

   3. AOF、RDB
   > 两者共存时，启动服务时，默认先加载AOF文件。如果AOF文件出错，使用**redis-check-aof --fix filename**进行恢复便可；若RDB出错，使用**redis-check-rdb --fix filename**。  
    >  shutdown、flushall（数据为空）会触发写rdb。save直接触发、bgsave异步操作。  
  > rewrite时会在配置文件**auto-aof-rewrite-min-size 64mb**达到时会启用重写。  

4. 事务
    multi 准备  
    ...  
    ...  
    exec执行 or discard放弃 
    注： 
      事务是部分支持，因为： 
        1，加入事务时，若命令出现运行时异常，会报错，但exec其它会生效。 
        2，加入事务时，若命令本身出现错误，EXEC后不会生效。 
        
     锁： 
     watch [name]   
     mutil 
     ... 
     exec /  unwatch 
    
5. 消息  
    > subscribe  k1 --- 发布后这边会收到订阅的消息。    
    > publish k1 value 
6. 主从复制  
     slaveof 127.0.0.1 6379 --直接使其此机的REDIS为IP127.0.0.1的从机。所有的KEY/VALUE全部立刻生效。 
     1，从机执行写命令会失败，master是写，slave是读。 
     2，主机down掉，从机还会是从机，不会变更为主机。 

        > 若没有更改配置文件，从机DOWN掉，会变为主机，丢失主从关系。需要 手动再次输入slaveof 命令。 
        > 若执行slaveof no one使用其从机变为主机，将另外从机指定本机，关系重新建立。当之前的master正常启动时，将脱离主从关系，变为单独的master。 

     3, 管理Redis，自动实现redis主机down掉，某一slave变更master且其它“从机”指向新master。

     > **sentinel.conf** 可监听redis，并实现当主库down掉时，自动切换某一从库为主库，其它“从库”指向新的master。即使down的master恢复后，redis会再次使用投票机制，决定谁是master，并将其它从库指向新的master。 

     **sentinel.conf内容及实现方式**
        - sentinel.conf's contents：
            > sentinel monitor 127.0.0.1 6379 1
            
            > sentinel down-after-milliseconds mymaster 60000
            
     	   > sentinel failover-timeout mymaster 180000
            
            > sentinel parallel-syncs mymaster 1

        - 实现
          

       ``
          #>redis-sentinel /usr/local/redis/conf/sentinel.conf

       ```
       
       ```

         监控本机6379端口的Redis，当down时，从机投票超过1票的为主机，其它为从机。

7.  其它命令

	root@ba7f750bb501:~#> redis-cli   
        127.0.0.1:6379> info replication --查看主从配置   
        127.0.0.1:6379> salveof 127.0.0.1 6379  --手动实现主从，需要在从机执行提向master    
	127.0.0.1:6379>sinter k1 k2 k3 ---并集  
	127.0.0.1:6379>sunion k1 k2 k3 ---合集  
	127.0.0.1:6379>sdiff k1 k2 k3  ---差集,针对K1除K2/K3外的差集。  


	ttl key //查看有效期
	    set k v exp//设置有效期

8.配置文件
	redis.conf
           daemond yes#标记为后台运行。


# 数据库

## 图形数据库
### neo4j
neo4j使用cql进行执行命令，参考 https://www.w3cschool.cn/neo4j/delete.html 具体命令。

基本:
>  create (user:User  {id:1,name:'cuiyingnan'})
>  match (user:User) where user.id = 1 return user.id,user.name
>  match (user:User) return user.name union all match (user:User) return user.name skip 1 limit 2
>  create index on : User(id)
>查看索引命令
>  :schema  
>  drop  index on : User(id)
> CREATE CONSTRAINT on (user:User) assert user.name is unique
> drop constraint on (user:User) assert user.name is unique

## 关系型数据库
###  Mysql

>导入文本命名：

	load data local infile 'C:/Users/cc/Downloads/aa.txt' into table tmp fields terminated by ',';

> SHOW TABLE STATUS LIKE 'user' -- 查看 表结构属性
> -- mysql读取顺序,以最后一次找到的位置为生效。  
  1,/etc/my.cnf  
  2,/etc/mysql/my.cnf  
  3,$MYSQL/my.cnf  
  4,--default-extra-file = /path/my.cnf  
  5,~/my.cnf  
> mysqld --help --verbose --显示可配置的全部命令  

>数据库引擎InnoDB/MYISAM
	其中两上个引擎全部是B+Tree进行的索引，区别在于InnoDB在链表存在是数据文件本身就是索引文件，而MyISAM在链表存在时，存储的是值的地址；
	以上特性致使：   
	a. InnoDB不适合字段值比较大的表，且有过多重复值的字段上进行索引，不可在text建立索引；删除时一行一行的删除 ；数据表文件比较大；
	b.删除时，一次性删除；数据表文件比较小；

索引类型：
	btree
	哈希
	普通
	惟一
	主键
	全文索引，一般不常用。比较慢。

针对于大表，时间长了以后，会出现过多的碎片，故使用sql>OPTIMIZE TABLE tableName；这样可以使数据库重新整理碎片，优化存储空间。


## no-sql数据库
### MongDB
#####  通用说明
https://www.mongodb.com直接下载使用，类似自己写了一个文件系统，只不过做得优化比较全。
如：
  分布式支持比较好；
  在高负载的情况下，速度比较快；
  存储以key-value存储（如JSON);
  架构分为：分片集群和复制集群（Replica set & Sharding cluster）
  优化方法:大集合拆分、建立索引（尽量建少的索引，会引起写慢），TTL设置索引。



全用MapReduce可以在命令中完成计算（如select中增加了部分程序功能）。
包含全文检索功能：
	1.开启此功能
	mongod --setParameter textSearchEnabled=true
	2.使用
	db.posts.find({$text:{$search:"runoob"}})

##### 启动
	#mongod.exe --dbpath C:\MongoDB\data    //启动数据库
	#mongo.exe
##### 增、删、改、查
	>use hi  //如果存在hi库则返回，如果不存在，则创建
	>db.getCollection('hi').find({})
	>db.ss.insert({name:"cuiyingnan",sex:"男"})
	>db.dropDatabases() //删除库
	>
	>show dbs//显示数据库
	>show collections //显示集合【类似数据库中的具体哪些表】
	>db.ss.drop //删除集合
	>db.dropDatabase//删除库，前提先use 某个库进去后再drop.
	>db.stats()//当前库状态
	>db.getName()//当前库
	>db.save与db.insert区别为：insert一直是插入，如果ID重复，提示错误；而save类似saveUpdate,如果存在则变更为更新操作。
	>db.hi.update({条件},{替换},true)//则判断条件是否存在，如果不存在直接保存新值；如果有的话，更新操作。

#### 修改器
	$set
	$inc
	$unset
	$push
	$pushAll// 批量增加 
	$addToSet
	$search
	......具体参照API。

##### 注意事项
	$size不对与其它比较字符一起使用，如 统计某数组大于3的数量且某项小于2的；变相实现，将某数组的长度以size存储。

###### 集群
	./mongod --master --dbpath /data/masterdb/      #主节点  
	
	./mongod --slave --source <masterip:masterport> --dbpath /data/slavedb/     备节点

###### 支持存储过程
	它是javascript写的，保存在db.system.js表中。

###### 导入
	mongoimport -d iflashbuy_log -c  testDB C:\Users\cc\Desktop\joson\bim_space.json

## <a name="Ngix" />Ngix

	命令：  
	#./nginx -t		//测试ngix.conf是否正确
	#./nginx -s reload	//重启

## <a name="Tomcat" />Tomcat

	日志中文：在catalina.sh中增加：
	JAVA_OPTS="$JAVA_OPTS $JSSE_OPTS -Dfile.encoding=utf-8"
使用Keepalived来保证单点的nginx故障，引起全部服务不能访问。并非nginx集群，类似数据库主备且没有实现读写分离。

## <a name="JenKins" />JenKins
	1,download JenKins at https://jenkins.io/
	2,>java -jar jenkins.war --httpPort=8080
	3, http://127.0.0.1:8080
启动系统后，开始进行新建工程及相关配置。
配置时：
    1，源码管理
        在此配置subversion or git的远程地址和登录用户名密码。
    2，构建触发器（使用默认）
    3，构建环境（使用默认）
    4，构建
        若是Maven项目，若无此配置，需在系统管理中增加maven,（invoke top-level maven targets）配置 clean package。
    5，构建后操作
        在系统管理中增加send build artifacts over SSH插件，进行远程发送，并执行远程命令。
        1，系统管理中增加远程连接及配置相关的用户名密码；
        2，在项目构建后操作输入需要发送的source，选择去头尾后的名字，发送成功后执行远程的脚本命令。



## <a name="Hadoop" />Hadoop

结构：
	master:
		NameNode 与 JobTracker  可放在一台机器上
		Secondary NameNode 	可放在一台机器上
		
	slave:
		DataDode与TaskTracer	可放一台机器上

## ElasticSearch  6.5.4
同为搜索引擎的Solar对比：

>　（1）二者安装都很简单。
>　（2）Solr 利用 Zookeeper 进行分布式管理，而 Elasticsearch 自身带有分布式协调管理功能。
>　（3）Solr 支持更多格式的数据，比如JSON、XML、CSV，而 Elasticsearch 仅支持json文件格式。
>　（4）Solr 官方提供的功能更多，而 Elasticsearch 本身更注重于核心功能，高级功能多有第三方插件提供
>　（5）Solr 在传统的搜索应用中表现好于 Elasticsearch，但在处理实时搜索应用时效率明显低于 Elasticsearch。
>　（6）Solr 是传统搜索应用的有力解决方案，但 Elasticsearch 更适用于新兴的实时搜索应用。
> 引：https://www.cnblogs.com/zlslch/p/6612639.html

### 存储相关
#### 信息存储位置
信息储层是依据下方公式进行：

	shard = hash(routing) % number_of_primary_shards
	routing 是一个可变值，默认是文档的 _id ，也可以设置成一个自定义的值。 routing 通过 hash 函数生成一个数字，然后这个数字再除以 number_of_primary_shards （主分片的数量）后得到 余数 。这个分布在 0 到 number_of_primary_shards-1 之间的余数，就是我们所寻求的文档所在分片的位置。

这就解释了为什么我们要在创建索引的时候就确定好主分片的数量 并且永远不会改变这个数量：因为如果数量变化了，那么所有之前路由的值都会无效，文档也再也找不到了。

#### 分片
	分片默认使用*1.5或3倍进行，如正常使用4个分片就满足需求，在设计上最大使用4*3 =12个node即可。官网建议每个分片30G大小。
	副本，稍后深入时继续。目前暂不是很清楚。

### 并发相关

ES在并发时，使用version进行并发控制，或批定version号 ，如
> version=5&version_type=external 
来进行线程的安全。
参见官网https://www.elastic.co/guide/cn/elasticsearch/guide/current/optimistic-concurrency-control.html。







----------------------
数学 ：

###1,关系
####数学关系等式：

	非 (A且B) = 非A 或 非B
	非（A或B） = 非A 且 非B

####3阶幻方或N阶幻方：
     
	参照印象笔记。








````

````